{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e6b31",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from nnfs.datasets import spiral_data\n",
    "import numpy as np\n",
    "import nnfs\n",
    "nnfs.init()\n",
    "import matplotlib.pyplot as plt\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3313ee0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='brg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c6fc7f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "nnfs.init()\n",
    "\n",
    "class Layer_Dense:\n",
    " def __init__(self, n_inputs, n_neurons):\n",
    "\n",
    "   self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "   self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    " def forward(self, inputs):\n",
    "   self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "dense1.forward(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cbb981",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(dense1.output[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807aceda",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    " def forward(self, inputs):\n",
    "  self.output = np.maximum(0, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc9b96e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X, y = spiral_data(samples=100, classes=3)\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "activation1 = Activation_ReLU()\n",
    "dense1.forward(X)\n",
    "\n",
    "activation1.forward(dense1.output)\n",
    "print(activation1.output[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011dcfe7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "A = [[1, 2, 3], [4, 5, 6], [7, 8,9]]\n",
    "print(np.sum(A))\n",
    "\n",
    "print(np.sum(A, axis = 0))\n",
    "print(np.sum(A, axis = 0).shape)\n",
    "\n",
    "print(np.sum(A, axis = 1))\n",
    "print(np.sum(A, axis = 1).shape)\n",
    "\n",
    "print(np.sum(A, axis = 0,keepdims = True))\n",
    "print(np.sum(A, axis = 0,keepdims = True).shape)\n",
    "\n",
    "print(np.sum(A, axis = 1,keepdims = True))\n",
    "print(np.sum(A, axis = 1,keepdims = True).shape)\n",
    "\n",
    "print(np.max(A, axis = 0))\n",
    "print(np.max(A, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ed7fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    " def forward(self, inputs):\n",
    "  exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "  probabilities = exp_values / np.sum(exp_values, axis=1,keepdims=True)\n",
    "  self.output = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e164cebb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X, y = spiral_data(samples=100, classes=3)\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "activation1 = Activation_ReLU()\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "dense1.forward(X)\n",
    "\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "print(activation2.output[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5667867c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
    " [0.1, 0.5, 0.4],\n",
    " [0.02, 0.9, 0.08]])\n",
    "class_targets = [0, 1, 1]\n",
    "print(softmax_outputs[[0, 1, 2], class_targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40b3f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(-np.log(softmax_outputs[\n",
    " range(len(softmax_outputs)), class_targets\n",
    "]))\n",
    "neg_log = -np.log(softmax_outputs[\n",
    " range(len(softmax_outputs)), class_targets\n",
    " ])\n",
    "average_loss = np.mean(neg_log)\n",
    "print(average_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2001068",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "y_true_check = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "y_pred_clipped_check = np.array([\n",
    "    [0.2, 0.7, 0.1],\n",
    "    [0.8, 0.1, 0.1],\n",
    "    [0.1, 0.2, 0.7]\n",
    "])\n",
    "\n",
    "y_true_check*y_pred_clipped_check\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d728e5b3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Loss:\n",
    " def calculate(self, output, y):\n",
    "\n",
    "  sample_losses = self.forward(output, y)\n",
    "  data_loss = np.mean(sample_losses)\n",
    "  return data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc65952",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
    " [0.1, 0.5, 0.4],\n",
    " [0.02, 0.9, 0.08]])\n",
    "class_targets = np.array([[1, 0, 0],\n",
    " [0, 1, 0],\n",
    " [0, 1, 0]])\n",
    "loss_function = Loss_CategoricalCrossentropy()\n",
    "loss = loss_function.calculate(softmax_outputs, class_targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f07a94",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X, y = spiral_data(samples=100, classes=3)\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "activation1 = Activation_ReLU()\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "activation2 = Activation_Softmax()\n",
    "loss_function = Loss_CategoricalCrossentropy()\n",
    "\n",
    "dense1.forward(X)\n",
    "\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "print(activation2.output[:5])\n",
    "loss = loss_function.calculate(activation2.output, y)\n",
    "print('loss:', loss)\n",
    "\n",
    "predictions = np.argmax(activation2.output, axis=1)\n",
    "if len(y.shape) == 2:\n",
    " y = np.argmax(y, axis=1)\n",
    "accuracy = np.mean(predictions == y)\n",
    "print('acc:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
